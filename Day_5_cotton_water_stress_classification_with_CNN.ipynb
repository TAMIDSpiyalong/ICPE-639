{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAMIDSpiyalong/ICPE-639/blob/main/Day_5_cotton_water_stress_classification_with_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfsA1GeALRJO"
      },
      "source": [
        "# Image Classification with the Cotton Image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD14Yr_ALRJO"
      },
      "source": [
        "In this section we will do the \"Hello World\" of deep learning: training a convolutional neural network (CNN) model to correctly classify the cotton water stress."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCa1oHjrLRJO"
      },
      "source": [
        "## Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdK-fBF_LRJO"
      },
      "source": [
        "* Understand how deep learning can solve problems traditional programming methods cannot\n",
        "* Learn about the [cotton image dataset](http://yann.lecun.com/exdb/mnist/)\n",
        "* Use the [Keras API](https://keras.io/) to load the MNIST dataset and prepare it for training\n",
        "* Create a simple convolutional neural network to perform image classification\n",
        "* Train the convolutional neural network using the prepped cotton image dataset\n",
        "* Observe the performance of the trained CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXBqPRScLRJO"
      },
      "source": [
        "## The Problem: Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOLo2LqSLRJO"
      },
      "source": [
        "In traditional programming, the programmer is able to articulate rules and conditions in their code that their program can then use to act in the correct way. This approach continues to work exceptionally well for a huge variety of problems.\n",
        "\n",
        "Image classification, which asks a program to correctly classify an image it has never seen before into its correct class, is near impossible to solve with traditional programming techniques. How could a programmer possibly define the rules and conditions to correctly classify a huge variety of images, especially taking into account images that they have never seen?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYVRkEdpLRJP"
      },
      "source": [
        "## The Solution: Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxBSZD-ILRJP"
      },
      "source": [
        "Deep learning excels at pattern recognition by trial and error. By training a deep neural network, such as CNN, with sufficient data, and providing the network with feedback on its performance via training, the network can identify, though a huge amount of iteration, its own set of conditions by which it can act in the correct way.\n",
        "\n",
        "In this section, we loaded the dataset to show what the dataset looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTJlfj-fPBw_",
        "outputId": "3858b71a-a671-4cef-b889-aaea03cb5df9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eO-HPtcPOLN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import sys\n",
        "import numpy\n",
        "# The skimage library has several different methods of thresholding\n",
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.color\n",
        "import skimage.filters\n",
        "from skimage.morphology import opening, closing, erosion, dilation\n",
        "from skimage.morphology import disk  # noqa\n",
        "from skimage.color import rgb2lab\n",
        "class_names = ['rainfed', 'fully irrigated', 'percent deficit', 'time delay']\n",
        "numpy.set_printoptions(threshold=sys.maxsize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIpK2vUfPeJW",
        "outputId": "f29d96dc-5de9-45b7-9fd7-dc3640820528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "# During the class, please ask the students to change the following data path to where they saved the dataset\n",
        "%cd 'drive/MyDrive/Colab Notebooks'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-TPRH-A-gzPb",
        "outputId": "20666ed3-4be5-4ae8-a1f4-809228a69f74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUR0DZHCPeMT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "52c97ccf-366d-463b-ece4-e9188826fcf5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a5c5b50917e9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# During the class, please ask the students to change the following data path to where they saved the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/twri_rgb_6832_cotton_64x64_9_02.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'labels_rgb.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/twri_rgb_6832_cotton_64x64_9_02.npy'"
          ]
        }
      ],
      "source": [
        "# During the class, please ask the students to change the following data path to where they saved the dataset\n",
        "data = np.load('/content/drive/MyDrive/Colab Notebooks/twri_rgb_6832_cotton_64x64_9_02.npy')\n",
        "labels = pd.read_csv('labels_rgb.csv')\n",
        "y_label = labels['class'].values\n",
        "\n",
        "new_data_without_filler = np.zeros((5376, 64, 64, 3))\n",
        "new_y_label_without_filler = np.zeros(5376, dtype=int)\n",
        "i = 0\n",
        "for idx, val in enumerate(y_label):\n",
        "  if val != 0:\n",
        "    new_data_without_filler[i] = data[idx]\n",
        "    new_y_label_without_filler[i] = y_label[idx]\n",
        "    i+=1\n",
        "data = new_data_without_filler\n",
        "y_label = new_y_label_without_filler - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5VkH8ETP3Pb"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4EghrzxP8qk"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "Counter(y_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPdgWBwFLRJP"
      },
      "source": [
        "## The Cotton Image Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMaejZkZLRJP"
      },
      "source": [
        "The study aimed to classify cotton water stress using advanced CNN models. The cotton image was collected by a UAV system at Lubbock, Texas. A DJI Phantom 4 was utilized as the UAV platform for collecting high-resolution RGB images at an altitude of 90 meters. The UAV image was preprocessed with ArcGIS Pro, which created 6832 images for each sampling date."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1c-AI-wLRJP"
      },
      "source": [
        "*Here* are 25 of the images included in the cotton image dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtiXattCQb5Q"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(data[i]/255)\n",
        "    # The CIFAR labels happen to be arrays,\n",
        "    # which is why you need the extra index\n",
        "    plt.xlabel(class_names[y_label[i]])\n",
        "plt.show() # because we did not shuffle the dataset yet, that's why the first 25 images all come from class 0, which is \"rainfed\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9NOYIMFLRJP"
      },
      "source": [
        "## Training and Validation Data and Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd02oAw2LRJP"
      },
      "source": [
        "When working with images for deep learning, we need both the images themselves, usually denoted as `X`, and also, correct [labels](https://developers.google.com/machine-learning/glossary#label) for these images, usually denoted as `Y`. Furthermore, we need `X` and `Y` values both for *training* the model, and then, a separate set of `X` and `Y` values for *validating* the performance of the model after it has been trained. Therefore, we need 4 segments of data for the cotton image dataset:\n",
        "\n",
        "1. `x_train`: Images used for training the CNN model\n",
        "2. `y_train`: Correct labels for the `x_train` images, used to evaluate the model's predictions during training\n",
        "3. `x_valid`: Images set aside for validating the performance of the model after it has been trained\n",
        "4. `y_valid`: Correct labels for the `x_valid` images, used to evaluate the model's predictions after it has been trained\n",
        "\n",
        "The process of preparing data for analysis is called [Data Engineering](https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7). To learn more about the differences between training data and validation data (as well as test data), check out [this article](https://machinelearningmastery.com/difference-test-validation-datasets/) by Jason Brownlee."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc6W5dI6LRJQ"
      },
      "source": [
        "## Loading the Data Into Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n5yur7dLRJQ"
      },
      "source": [
        "There are many [deep learning frameworks](https://developer.nvidia.com/deep-learning-frameworks), each with their own merits. In this workshop we will be working with [Tensorflow 2](https://www.tensorflow.org/tutorials/quickstart/beginner), and specifically with the [Keras API](https://keras.io/). Keras has many useful built in functions designed for the computer vision tasks. It is also a legitimate choice for deep learning in a professional setting due to its [readability](https://blog.pragmaticengineer.com/readable-code/) and efficiency, though it is not alone in this regard, and it is worth investigating a variety of frameworks when beginning a deep learning project.\n",
        "\n",
        "One of the many helpful features that Keras provides are modules containing many helper methods for [many common datasets](https://www.tensorflow.org/api_docs/python/tf/keras/datasets).\n",
        "\n",
        "We will begin by partitioning the cotton image dataset into training and testing with train_test_split method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qmaLmRKLRJQ"
      },
      "outputs": [],
      "source": [
        "# the data, split between train and validation sets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(data, y_label, test_size=0.3, random_state=42)\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIr1J2u0LRJQ"
      },
      "source": [
        "## Exploring the Cotton Image Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oua_E9ILRJR"
      },
      "source": [
        "We stated above that the cotton image dataset contained 5376 RGB images of cotton canopy. By executing the following cells, we can see that Keras has partitioned 3763 of these images for training, and 1613 for validation (after training), and also, that each image itself is a 3D array with the dimensions 64x64x3:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "br8lcxiWLRJR"
      },
      "outputs": [],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMnIOfOPLRJR"
      },
      "outputs": [],
      "source": [
        "test_images.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRTOnkOkLRJR"
      },
      "source": [
        "Furthermore, we can see that these 64x64x3 images are represented as a collection of float64 values between 0.0 and 1.0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "497rpqOWLRJR"
      },
      "outputs": [],
      "source": [
        "train_images.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6TSMqU3LRJR"
      },
      "outputs": [],
      "source": [
        "train_images.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jj-0FBKcLRJR"
      },
      "outputs": [],
      "source": [
        "train_images.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2UQ154jLRJR"
      },
      "source": [
        "Using [Matplotlib](https://matplotlib.org/), we can render one of these grayscale images in our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPXNCFQTLRJR"
      },
      "outputs": [],
      "source": [
        "image = train_images[0]\n",
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b-193p4LRJR"
      },
      "source": [
        "In this way we can now see that this is a 64x64x3 pixel image of a cotton canopy. What is the corresponding label? The answer is in the `train_labels` data, which contains correct labels for the data. Remember that class_names = ['rainfed'(0), 'fully irrigated' (1), 'percent deficit' (2), 'time delay' (3)]. Let's take a look:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHeMd0B5LRJR"
      },
      "outputs": [],
      "source": [
        "train_labels[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBUhptzxXSHX"
      },
      "source": [
        "Now, let's display the first 25 images in the train_images. What can we expect?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPUL98j4XLVN"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i]) # pay attention that this time we did not divide the train_images by 255, why?\n",
        "    # The CIFAR labels happen to be arrays,\n",
        "    # which is why you need the extra index\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksU806O4X4nU"
      },
      "source": [
        "Wow! Our train_images were randomly shuffled by train_test_split method. We just displayed images from all the four classes.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D5Xw8uLLRJa"
      },
      "source": [
        "## Creating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCR55RO_LRJa"
      },
      "source": [
        "With the data prepared for training, it is now time to create the model that we will train with the data. This first basic model will be made up of several *layers* and will be comprised of 3 main parts:\n",
        "\n",
        "1. An input layer, which will receive data in some expected format\n",
        "2. Several [hidden layers](https://developers.google.com/machine-learning/glossary#hidden-layer), each comprised of many *neurons*. Each [neuron](https://developers.google.com/machine-learning/glossary#neuron) will have the ability to affect the network's guess with its *weights*, which are values that will be updated over many iterations as the network gets feedback on its performance and learns\n",
        "3. An output layer, which will depict the network's guess for a given image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Fh6L8kcLRJb"
      },
      "source": [
        "### Instantiating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSwMd0UfLRJb"
      },
      "source": [
        "To begin, we will use Keras's [Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model class to instantiate an instance of a model that will have a series of layers that data will pass through in sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzGI8YSNLRJb"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-pmphorLRJb"
      },
      "source": [
        "### Creating the Input Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mk2ylg3LRJb"
      },
      "source": [
        "Next, we will add the input Conv2D layers and MaxPooling2D layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reK25bubLRJb"
      },
      "source": [
        "We will use the `relu` activation function, which in short, will help our network to learn how to make more sophisticated guesses about data than if it were required to make guesses based on some strictly linear function.\n",
        "\n",
        "The `input_shape` value specifies the shape of the incoming data which in our situation is a 3D array of 64x64x3:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2gnFIF2LRJb"
      },
      "outputs": [],
      "source": [
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2AKUPE5LRJb"
      },
      "source": [
        "Now we will add an additional densely connected layer. Again, much more will be said about these later, but for now know that these layers give the network more parameters to contribute towards its guesses, and therefore, more subtle opportunities for accurate learning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RjqWoQFLRJb"
      },
      "outputs": [],
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWxTIvuqLRJc"
      },
      "source": [
        "### Creating the Output Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqaUbs_mLRJc"
      },
      "source": [
        "Finally, we will add an output layer. This layer result in each of the layer's values being a probability between 0 and 1 and will result in all the outputs of the layer adding to 1. In this case, since the network is to make a guess about a single image belonging to 1 of 4 possible irrigation levels, there will be 4 outputs. Each output gives the model's guess (a probability) that the image belongs to that specific class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWMIbhDXLRJc"
      },
      "outputs": [],
      "source": [
        "model.add(layers.Dense(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2tw2SKcLRJc"
      },
      "source": [
        "### Summarizing the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx9pB7tELRJc"
      },
      "source": [
        "Keras provides the model instance method [summary](https://www.tensorflow.org/api_docs/python/tf/summary) which will print a readable summary of a model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyVh7wH5LRJc"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6mWZpqlLRJc"
      },
      "source": [
        "Note the number of trainable parameters. Each of these can be adjusted during training and will contribute towards the trained model's guesses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQfAe2hPLRJc"
      },
      "source": [
        "### Compiling the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsXUd4ukLRJc"
      },
      "source": [
        "Again, more details are to follow, but the final step we need to do before we can actually train our model with data is to [compile](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#compile) it. Here we specify a [loss function](https://developers.google.com/machine-learning/glossary#loss) which will be used for the model to understand how well it is performing during training. We also specify that we would like to track `accuracy` while the model trains:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFo80BUdLRJd"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzLN3Gy5LRJd"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jJH2aFkLRJd"
      },
      "source": [
        "Now that we have prepared training and validation data, and a model, it's time to train our model with our training data, and verify it with its validation data.\n",
        "\n",
        "\"Training a model with data\" is often also called \"fitting a model to data.\" Put this latter way, it highlights that the shape of the model changes over time to more accurately understand the data that it is being given.\n",
        "\n",
        "When fitting (training) a model with Keras, we use the model's [fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) method. It expects the following arguments:\n",
        "\n",
        "* The training data\n",
        "* The labels for the training data\n",
        "* The number of times it should train on the entire training dataset (called an *epoch*)\n",
        "* The validation or test data, and its labels\n",
        "\n",
        "Run the cell below to train the model. We will discuss its output after the training completes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDUMt_Q7LRJd"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_images, train_labels, epochs=70,\n",
        "                      validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPlvS34hLRJd"
      },
      "source": [
        "### Observing Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7x7NLTKLRJd"
      },
      "source": [
        "For each of the epoch, notice the `accuracy` and `val_accuracy` scores. `accuracy` states how well the model did for the epoch on all the training data. `val_accuracy` states how well the model did on the validation data, which if you recall, was not used at all for training the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgEEUMeggPs3"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1.2])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsd1UJU5LRJd"
      },
      "source": [
        "The model did quite well! The accuracy quickly reached close to 100%. The validation accuracy was around 87%. Consider it was a first trial without many paramerter tunings, the model performed very well. We now have a model that can be used to accurately detect and classify cotton water stress.\n",
        "\n",
        "The next step would be to use this model to classify new not-yet-seen cotton canopy images. This is called [inference](https://blogs.nvidia.com/blog/2016/08/22/difference-deep-learning-training-inference-ai/). We'll explore the process of inference in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxavwLHILRJd"
      },
      "source": [
        "## The performance evaluation of CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7x7XezeLRJd"
      },
      "source": [
        "In order to evaluate the performance of the trained CNN models, we can employe a confusion matrix, which provides a comprehensive summary of the prediction results in a classification problem. The confusion matrix helps in understanding not only the overall accuracy of the classifier but also the specific types of errors being made."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probability_model = tf.keras.Sequential([model,\n",
        "                                         tf.keras.layers.Softmax()])\n",
        "predictions = probability_model.predict(test_images)\n",
        "pred = np.argmax(predictions, axis=1)\n",
        "tf.math.confusion_matrix(test_labels, pred)\n",
        "\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "ConfusionMatrixDisplay.from_predictions(test_labels, pred)"
      ],
      "metadata": {
        "id": "h4Vf9KjVkSPb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}